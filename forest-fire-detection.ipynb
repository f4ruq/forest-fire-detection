{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2025144,"sourceType":"datasetVersion","datasetId":1212187},{"sourceId":2890158,"sourceType":"datasetVersion","datasetId":1770494},{"sourceId":6633136,"sourceType":"datasetVersion","datasetId":3829311},{"sourceId":7863205,"sourceType":"datasetVersion","datasetId":3655844},{"sourceId":8904920,"sourceType":"datasetVersion","datasetId":5353840},{"sourceId":13137563,"sourceType":"datasetVersion","datasetId":8323092},{"sourceId":13146247,"sourceType":"datasetVersion","datasetId":8329010},{"sourceId":13150171,"sourceType":"datasetVersion","datasetId":8331746}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:16:56.623309Z","iopub.execute_input":"2025-09-24T08:16:56.623994Z","iopub.status.idle":"2025-09-24T08:18:12.906007Z","shell.execute_reply.started":"2025-09-24T08:16:56.623969Z","shell.execute_reply":"2025-09-24T08:18:12.905280Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"0) Kurulum & İçeri Aktarım","metadata":{}},{"cell_type":"code","source":"import os, pathlib, numpy as np, matplotlib.pyplot as plt, warnings\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:18:24.336955Z","iopub.execute_input":"2025-09-24T08:18:24.337224Z","iopub.status.idle":"2025-09-24T08:18:44.941329Z","shell.execute_reply.started":"2025-09-24T08:18:24.337201Z","shell.execute_reply":"2025-09-24T08:18:44.940744Z"}},"outputs":[{"name":"stderr","text":"2025-09-24 08:18:28.308746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758701908.708458      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758701908.809007      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tf.config.optimizer.set_experimental_options({'layout_optimizer': False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:18:50.309380Z","iopub.execute_input":"2025-09-24T08:18:50.310284Z","iopub.status.idle":"2025-09-24T08:18:50.313989Z","shell.execute_reply.started":"2025-09-24T08:18:50.310252Z","shell.execute_reply":"2025-09-24T08:18:50.313275Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"1) Sabitler & Yol","metadata":{}},{"cell_type":"code","source":"SEED = 58\nIMG_SIZE = (160, 160)\nBATCH_SIZE = 32\nDATA_DIR = \"/kaggle/input/combined-forest-fire/combined_data/train\"\nTEST_DIR = \"/kaggle/input/combined-forest-fire/combined_data/test\"\nVAL_SPLIT = 0.2\nAUTOTUNE  = tf.data.AUTOTUNE\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:22:54.638170Z","iopub.execute_input":"2025-09-24T08:22:54.638707Z","iopub.status.idle":"2025-09-24T08:22:54.643192Z","shell.execute_reply.started":"2025-09-24T08:22:54.638683Z","shell.execute_reply":"2025-09-24T08:22:54.642499Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"2) Dataset Oluşturma (train/val otomatik böl)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.data import experimental as tfdata_exp\n\ntrain_ds = image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=VAL_SPLIT,\n    subset=\"training\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"rgb\"\n)\nval_ds = image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=VAL_SPLIT,\n    subset=\"validation\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"rgb\"\n)\n\nclass_names = train_ds.class_names\n\ntest_ds = image_dataset_from_directory(\n    TEST_DIR,\n    image_size=IMG_SIZE, batch_size=BATCH_SIZE, color_mode=\"rgb\",\n    shuffle=False,               \n    class_names=class_names        \n)\n\nNUM_CLASSES = len(class_names)\nprint(\"classes:\", class_names)\n\ntrain_ds = train_ds.apply(tfdata_exp.ignore_errors())\nval_ds = val_ds.apply(tfdata_exp.ignore_errors())\ntest_ds = test_ds.apply(tfdata_exp.ignore_errors())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:22:59.270535Z","iopub.execute_input":"2025-09-24T08:22:59.271136Z","iopub.status.idle":"2025-09-24T08:23:06.243036Z","shell.execute_reply.started":"2025-09-24T08:22:59.271109Z","shell.execute_reply":"2025-09-24T08:23:06.242462Z"}},"outputs":[{"name":"stdout","text":"Found 20620 files belonging to 2 classes.\nUsing 16496 files for training.\nFound 20620 files belonging to 2 classes.\nUsing 4124 files for validation.\nFound 2935 files belonging to 2 classes.\nclasses: ['fire', 'nonfire']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"3) Performans için önbellek & veri artırma (augmentation)","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n# performans\ntrain_ds = train_ds.shuffle(1024).prefetch(AUTOTUNE)\nval_ds   = val_ds.prefetch(AUTOTUNE)\n\n# augmentation katmanı (GPU'da çalışır)\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n], name=\"augmentation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:23:17.477502Z","iopub.execute_input":"2025-09-24T08:23:17.477963Z","iopub.status.idle":"2025-09-24T08:23:17.503848Z","shell.execute_reply.started":"2025-09-24T08:23:17.477940Z","shell.execute_reply":"2025-09-24T08:23:17.503141Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"4) Basit CNN– “baseline”\n","metadata":{}},{"cell_type":"code","source":"def build_baseline(input_shape=IMG_SIZE+(3,), num_classes=NUM_CLASSES):\n    inputs = layers.Input(shape=input_shape)\n    x = data_augmentation(inputs)\n    x = layers.Rescaling(1./255)(x)\n\n    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Dropout(0.3)(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(0.4)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    model = keras.Model(inputs, outputs, name=\"cnn_baseline\")\n    return model\n\nmodel = build_baseline()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:23:20.819825Z","iopub.execute_input":"2025-09-24T08:23:20.820107Z","iopub.status.idle":"2025-09-24T08:23:21.622123Z","shell.execute_reply.started":"2025-09-24T08:23:20.820086Z","shell.execute_reply":"2025-09-24T08:23:21.621623Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"cnn_baseline\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_baseline\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,553,728\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,728</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,647,234\u001b[0m (25.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,234</span> (25.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,647,234\u001b[0m (25.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,234</span> (25.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"5) Derleme, Callback’ler, Eğitim","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n    keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_loss\"),\n]\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=15,callbacks=callbacks)\n\nmodel.evaluate(test_ds, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:25:47.464526Z","iopub.execute_input":"2025-09-24T08:25:47.464803Z","iopub.status.idle":"2025-09-24T09:01:41.940373Z","shell.execute_reply.started":"2025-09-24T08:25:47.464781Z","shell.execute_reply":"2025-09-24T09:01:41.939741Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"    278/Unknown \u001b[1m122s\u001b[0m 41ms/step - accuracy: 0.8424 - loss: 0.4026","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\nInvalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 156ms/step - accuracy: 0.8426 - loss: 0.4021 - val_accuracy: 0.9199 - val_loss: 0.1995 - learning_rate: 0.0010\nEpoch 2/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 133ms/step - accuracy: 0.9306 - loss: 0.1706 - val_accuracy: 0.9453 - val_loss: 0.1620 - learning_rate: 0.0010\nEpoch 3/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9330 - loss: 0.1536","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 143ms/step - accuracy: 0.9330 - loss: 0.1536 - val_accuracy: 0.9231 - val_loss: 0.2203 - learning_rate: 0.0010\nEpoch 4/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9365 - loss: 0.1572","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 136ms/step - accuracy: 0.9365 - loss: 0.1571 - val_accuracy: 0.9470 - val_loss: 0.1423 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 132ms/step - accuracy: 0.9477 - loss: 0.1226 - val_accuracy: 0.9519 - val_loss: 0.1287 - learning_rate: 0.0010\nEpoch 6/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m271/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9490 - loss: 0.1238","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 128ms/step - accuracy: 0.9490 - loss: 0.1238 - val_accuracy: 0.9459 - val_loss: 0.1459 - learning_rate: 0.0010\nEpoch 7/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m274/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9488 - loss: 0.1244","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 140ms/step - accuracy: 0.9488 - loss: 0.1245 - val_accuracy: 0.9374 - val_loss: 0.1444 - learning_rate: 0.0010\nEpoch 8/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m279/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9482 - loss: 0.1115","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 138ms/step - accuracy: 0.9482 - loss: 0.1115 - val_accuracy: 0.9445 - val_loss: 0.1816 - learning_rate: 5.0000e-04\nEpoch 9/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m275/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9628 - loss: 0.0918","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 136ms/step - accuracy: 0.9628 - loss: 0.0919 - val_accuracy: 0.9542 - val_loss: 0.1170 - learning_rate: 5.0000e-04\nEpoch 10/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 137ms/step - accuracy: 0.9594 - loss: 0.0968 - val_accuracy: 0.9543 - val_loss: 0.1234 - learning_rate: 5.0000e-04\nEpoch 11/15\n\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9608 - loss: 0.0966","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 135ms/step - accuracy: 0.9609 - loss: 0.0966 - val_accuracy: 0.9535 - val_loss: 0.1164 - learning_rate: 5.0000e-04\nEpoch 12/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9625 - loss: 0.0914","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 134ms/step - accuracy: 0.9625 - loss: 0.0914 - val_accuracy: 0.9545 - val_loss: 0.1403 - learning_rate: 5.0000e-04\nEpoch 13/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m279/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9634 - loss: 0.0892","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 131ms/step - accuracy: 0.9634 - loss: 0.0892 - val_accuracy: 0.9583 - val_loss: 0.1304 - learning_rate: 5.0000e-04\nEpoch 14/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m276/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9638 - loss: 0.0867","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 133ms/step - accuracy: 0.9638 - loss: 0.0867 - val_accuracy: 0.9563 - val_loss: 0.1366 - learning_rate: 2.5000e-04\nEpoch 15/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 131ms/step - accuracy: 0.9660 - loss: 0.0829 - val_accuracy: 0.9506 - val_loss: 0.1402 - learning_rate: 2.5000e-04\n\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 472ms/step - accuracy: 0.9013 - loss: 0.2632\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[0.23083461821079254, 0.9135504364967346]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model.save(\"/kaggle/working/my_model.h5\")\n#model.save_weights(\"/kaggle/working/my_model.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:04:14.164515Z","iopub.execute_input":"2025-09-24T09:04:14.164790Z","iopub.status.idle":"2025-09-24T09:04:14.409985Z","shell.execute_reply.started":"2025-09-24T09:04:14.164769Z","shell.execute_reply":"2025-09-24T09:04:14.409198Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"Tek görseli tahmin et (top-1 olasılıkla)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np, pathlib\n\n# IMG_SIZE ve class_names önceki hücrelerden geliyor\ndef predict_image(img_path, model, img_size=IMG_SIZE, class_names=class_names):\n    # Güvenli RGB + yeniden boyutlandırma\n    img = load_img(img_path, target_size=img_size, color_mode=\"rgb\")\n    arr = img_to_array(img)              # (H,W,3), dtype=float32, 0..255\n    arr = np.expand_dims(arr, axis=0)    # (1,H,W,3)\n\n    # Tahmin\n    probs = model.predict(arr, verbose=0)[0]          # (num_classes,)\n    idx   = int(np.argmax(probs))\n    pred  = class_names[idx]\n    conf  = float(probs[idx])\n\n    return {\"path\": str(img_path), \"pred\": pred, \"conf\": conf, \"probs\": probs}\n\n# KULLANIM:\n# 1) Kaggle'da \"Add data\" → kendi görsellerini bir dataset olarak ekle veya\n# 2) /kaggle/working içine upload et (Notebook arayüzünden).\nTEST_IMG = \"/kaggle/input/testtest/testdata/nonfiretest/NF_9.jpg\"  # <-- kendi dosya yolunu yaz\nres = predict_image(TEST_IMG, model)\nprint(f\"Pred: {res['pred']}  |  conf: {res['conf']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:03:13.591758Z","iopub.execute_input":"2025-09-24T09:03:13.592053Z","iopub.status.idle":"2025-09-24T09:03:14.167284Z","shell.execute_reply.started":"2025-09-24T09:03:13.592031Z","shell.execute_reply":"2025-09-24T09:03:14.166559Z"}},"outputs":[{"name":"stdout","text":"Pred: nonfire  |  conf: 0.984\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model.save_weights(\"/kaggle/working/fire_nonfire.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T17:28:02.248712Z","iopub.execute_input":"2025-09-23T17:28:02.249503Z","iopub.status.idle":"2025-09-23T17:28:02.432774Z","shell.execute_reply.started":"2025-09-23T17:28:02.249469Z","shell.execute_reply":"2025-09-23T17:28:02.431941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob, os\nfrom PIL import Image, UnidentifiedImageError\n\ndef predict_folder(folder_path, model, img_size=IMG_SIZE, class_names=class_names):\n    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\")\n    files = []\n    for e in exts:\n        files.extend(glob.glob(os.path.join(folder_path, e)))\n    results, bad = [], []\n\n    for p in files:\n        try:\n            # Önce açılıp RGB'ye çevrilebildiğini hızlıca kontrol edelim (bozukları atla)\n            with Image.open(p) as im:\n                im.convert(\"RGB\")\n            out = predict_image(p, model, img_size, class_names)\n            results.append(out)\n        except (UnidentifiedImageError, OSError):\n            bad.append(p)\n\n    # küçük bir özet tablosu\n    import pandas as pd\n    if results:\n        df = pd.DataFrame([{\"path\": r[\"path\"], \"pred\": r[\"pred\"], \"conf\": r[\"conf\"]} for r in results])\n        display(df.sort_values(\"conf\", ascending=False).reset_index(drop=True))\n        print(f\"\\nToplam: {len(results)} görüntü tahmin edildi. Atlanan (bozuk): {len(bad)}\")\n    else:\n        print(\"Hiç uygun görüntü bulunamadı.\")\n    if bad:\n        print(\"Atlanan (bozuk) örnekler (ilk 10):\")\n        for p in bad[:10]:\n            print(\" -\", p)\n\n# KULLANIM:\nTEST_DIR = \"/kaggle/input/testtest/testdata/firetest\"  # <-- klasör yolunu yaz (içinde .jpg/.png dosyaların olsun)\npredict_folder(TEST_DIR, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:03:19.560973Z","iopub.execute_input":"2025-09-24T09:03:19.561285Z","iopub.status.idle":"2025-09-24T09:03:20.446061Z","shell.execute_reply.started":"2025-09-24T09:03:19.561228Z","shell.execute_reply":"2025-09-24T09:03:20.445291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                path  pred      conf\n0   /kaggle/input/testtest/testdata/firetest/F_9.jpg  fire  1.000000\n1   /kaggle/input/testtest/testdata/firetest/F_6.jpg  fire  0.999459\n2   /kaggle/input/testtest/testdata/firetest/F_5.jpg  fire  0.997867\n3   /kaggle/input/testtest/testdata/firetest/F_8.jpg  fire  0.995633\n4  /kaggle/input/testtest/testdata/firetest/F_10.jpg  fire  0.986421\n5  /kaggle/input/testtest/testdata/firetest/F_11.jpg  fire  0.970741\n6   /kaggle/input/testtest/testdata/firetest/F_7.jpg  fire  0.967110","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>pred</th>\n      <th>conf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_9.jpg</td>\n      <td>fire</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_6.jpg</td>\n      <td>fire</td>\n      <td>0.999459</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_5.jpg</td>\n      <td>fire</td>\n      <td>0.997867</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_8.jpg</td>\n      <td>fire</td>\n      <td>0.995633</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_10.jpg</td>\n      <td>fire</td>\n      <td>0.986421</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_11.jpg</td>\n      <td>fire</td>\n      <td>0.970741</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>/kaggle/input/testtest/testdata/firetest/F_7.jpg</td>\n      <td>fire</td>\n      <td>0.967110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nToplam: 7 görüntü tahmin edildi. Atlanan (bozuk): 0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}