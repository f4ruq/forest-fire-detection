{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2025144,"sourceType":"datasetVersion","datasetId":1212187},{"sourceId":2890158,"sourceType":"datasetVersion","datasetId":1770494},{"sourceId":7863205,"sourceType":"datasetVersion","datasetId":3655844},{"sourceId":8904920,"sourceType":"datasetVersion","datasetId":5353840},{"sourceId":13137563,"sourceType":"datasetVersion","datasetId":8323092},{"sourceId":13150348,"sourceType":"datasetVersion","datasetId":8331746},{"sourceId":13156030,"sourceType":"datasetVersion","datasetId":8329010}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, pathlib, numpy as np, matplotlib.pyplot as plt, warnings\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T09:15:33.515409Z","iopub.execute_input":"2025-09-26T09:15:33.515579Z","iopub.status.idle":"2025-09-26T09:17:57.914743Z","shell.execute_reply.started":"2025-09-26T09:15:33.515563Z","shell.execute_reply":"2025-09-26T09:17:57.913886Z"}},"outputs":[{"name":"stderr","text":"2025-09-26 09:15:36.633524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758878136.971211      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758878137.060069      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#tf.config.optimizer.set_experimental_options({'layout_optimizer': False})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:34:11.824568Z","iopub.execute_input":"2025-09-25T08:34:11.825304Z","iopub.status.idle":"2025-09-25T08:34:11.830595Z","shell.execute_reply.started":"2025-09-25T08:34:11.825266Z","shell.execute_reply":"2025-09-25T08:34:11.829530Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"### ***Constants & File Path***","metadata":{}},{"cell_type":"code","source":"SEED = 58\nIMG_SIZE = (160, 160)\nBATCH_SIZE = 32\nDATA_DIR = \"/kaggle/input/combined-forest-fire/combined_data/train\"\nTEST_DIR = \"/kaggle/input/combined-forest-fire/combined_data/test\"\nVAL_SPLIT = 0.2\nAUTOTUNE = tf.data.AUTOTUNE\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:43:50.325219Z","iopub.execute_input":"2025-09-25T08:43:50.326077Z","iopub.status.idle":"2025-09-25T08:43:50.330219Z","shell.execute_reply.started":"2025-09-25T08:43:50.326053Z","shell.execute_reply":"2025-09-25T08:43:50.329604Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### ***Dataset Creation (train/val split)***","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.data import experimental as tfdata_exp\n\ntrain_ds = image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=VAL_SPLIT,\n    subset=\"training\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"rgb\"\n)\nval_ds = image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=VAL_SPLIT,\n    subset=\"validation\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    color_mode=\"rgb\"\n)\n\nclass_names = train_ds.class_names\n\ntest_ds = image_dataset_from_directory(\n    TEST_DIR,\n    image_size=IMG_SIZE, batch_size=BATCH_SIZE, color_mode=\"rgb\",\n    shuffle=False,               \n    class_names=class_names        \n)\n\nNUM_CLASSES = len(class_names)\nprint(\"classes:\", class_names)\n\ntrain_ds = train_ds.apply(tfdata_exp.ignore_errors())\nval_ds = val_ds.apply(tfdata_exp.ignore_errors())\ntest_ds = test_ds.apply(tfdata_exp.ignore_errors())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:43:56.970747Z","iopub.execute_input":"2025-09-25T08:43:56.971526Z","iopub.status.idle":"2025-09-25T08:44:18.274507Z","shell.execute_reply.started":"2025-09-25T08:43:56.971500Z","shell.execute_reply":"2025-09-25T08:44:18.273677Z"}},"outputs":[{"name":"stdout","text":"Found 20620 files belonging to 2 classes.\nUsing 16496 files for training.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1758789846.547760      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1758789846.548581      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Found 20620 files belonging to 2 classes.\nUsing 4124 files for validation.\nFound 2935 files belonging to 2 classes.\nclasses: ['fire', 'nonfire']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### ***Optimization & Data Augmentation***","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ntrain_ds = train_ds.shuffle(1024).prefetch(AUTOTUNE)\nval_ds   = val_ds.prefetch(AUTOTUNE)\n\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n], name=\"augmentation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:44:26.730628Z","iopub.execute_input":"2025-09-25T08:44:26.731282Z","iopub.status.idle":"2025-09-25T08:44:26.756190Z","shell.execute_reply.started":"2025-09-25T08:44:26.731259Z","shell.execute_reply":"2025-09-25T08:44:26.755507Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### ***Building Baseline***\n","metadata":{}},{"cell_type":"code","source":"def build_baseline(input_shape=IMG_SIZE+(3,), num_classes=NUM_CLASSES):\n    inputs = layers.Input(shape=input_shape)\n    x = data_augmentation(inputs)\n    x = layers.Rescaling(1./255)(x)\n\n    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.Dropout(0.3)(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(0.4)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    model = keras.Model(inputs, outputs, name=\"fire_predict\")\n    return model\n\nmodel = build_baseline()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:44:52.420917Z","iopub.execute_input":"2025-09-25T08:44:52.421647Z","iopub.status.idle":"2025-09-25T08:44:52.483837Z","shell.execute_reply.started":"2025-09-25T08:44:52.421623Z","shell.execute_reply":"2025-09-25T08:44:52.483141Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"fire_predict\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fire_predict\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling_1 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,553,728\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,728</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,647,234\u001b[0m (25.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,234</span> (25.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,647,234\u001b[0m (25.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,647,234</span> (25.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### ***Compiling, Callbacks and Model Training***","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n    keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_loss\"),\n]\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=15,callbacks=callbacks)\n\nmodel.evaluate(test_ds, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:45:02.916686Z","iopub.execute_input":"2025-09-25T08:45:02.916968Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1758789905.966745      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/fire_predict_1/dropout_2_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nInvalid SOS parameters for sequential JPEG\nInvalid SOS parameters for sequential JPEG\nI0000 00:00:1758790037.662601     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"    279/Unknown \u001b[1m149s\u001b[0m 41ms/step - accuracy: 0.8501 - loss: 0.3710","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 160ms/step - accuracy: 0.8502 - loss: 0.3706 - val_accuracy: 0.9271 - val_loss: 0.1598 - learning_rate: 0.0010\nEpoch 2/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\nInvalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 139ms/step - accuracy: 0.9267 - loss: 0.1754 - val_accuracy: 0.9412 - val_loss: 0.1323 - learning_rate: 0.0010\nEpoch 3/15\n","output_type":"stream"},{"name":"stderr","text":"Invalid SOS parameters for sequential JPEG\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m261/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9375 - loss: 0.1578","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### ***Model Saving (if needed)***","metadata":{}},{"cell_type":"code","source":"model.save(\"/kaggle/working/my_model.h5\")\n#model.save_weights(\"/kaggle/working/my_model.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:38:50.623602Z","iopub.status.idle":"2025-09-25T08:38:50.623912Z","shell.execute_reply.started":"2025-09-25T08:38:50.623776Z","shell.execute_reply":"2025-09-25T08:38:50.623788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ***Predict a Single Image (with Top-1 Probability)***","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np, pathlib\n\ndef predict_image(img_path, model, img_size=IMG_SIZE, class_names=class_names):\n    # Güvenli RGB + yeniden boyutlandırma\n    img = load_img(img_path, target_size=img_size, color_mode=\"rgb\")\n    arr = img_to_array(img)              # (H,W,3), dtype=float32, 0..255\n    arr = np.expand_dims(arr, axis=0)    # (1,H,W,3)\n\n    # Tahmin\n    probs = model.predict(arr, verbose=0)[0]          # (num_classes,)\n    idx   = int(np.argmax(probs))\n    pred  = class_names[idx]\n    conf  = float(probs[idx])\n\n    return {\"path\": str(img_path), \"pred\": pred, \"conf\": conf, \"probs\": probs}\n\nTEST_IMG = \"/kaggle/input/testtest/testdata/nonfiretest/NF_9.jpg\"\nres = predict_image(TEST_IMG, model)\nprint(f\"Pred: {res['pred']}  |  conf: {res['conf']:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:38:50.624721Z","iopub.status.idle":"2025-09-25T08:38:50.625015Z","shell.execute_reply.started":"2025-09-25T08:38:50.624885Z","shell.execute_reply":"2025-09-25T08:38:50.624898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_weights(\"/kaggle/working/fire_nonfire.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:38:50.627806Z","iopub.status.idle":"2025-09-25T08:38:50.628152Z","shell.execute_reply.started":"2025-09-25T08:38:50.628007Z","shell.execute_reply":"2025-09-25T08:38:50.628019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob, os\nfrom PIL import Image, UnidentifiedImageError\n\ndef predict_folder(folder_path, model, img_size=IMG_SIZE, class_names=class_names):\n    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\")\n    files = []\n    for e in exts:\n        files.extend(glob.glob(os.path.join(folder_path, e)))\n    results, bad = [], []\n\n    for p in files:\n        try:\n                # First, quickly check if it can be opened and converted to RGB (skip corrupted ones)            with Image.open(p) as im:\n                im.convert(\"RGB\")\n            out = predict_image(p, model, img_size, class_names)\n            results.append(out)\n        except (UnidentifiedImageError, OSError):\n            bad.append(p)\n\n    ## a small summary table\n    import pandas as pd\n    if results:\n        df = pd.DataFrame([{\"path\": r[\"path\"], \"pred\": r[\"pred\"], \"conf\": r[\"conf\"]} for r in results])\n        display(df.sort_values(\"conf\", ascending=False).reset_index(drop=True))\n        print(f\"\\nTotal: {len(results)} Image predicted. Skipped (corrupted): {len(bad)}\")\n    else:\n        print(\"No valid images found. \")\n    if bad:\n        print(\"Skipped (corrupted) samples (first 10):\")\n        for p in bad[:10]:\n            print(\" -\", p)\n\nTEST_DIR = \"/kaggle/input/testtest/testdata/firetest\" \npredict_folder(TEST_DIR, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T08:38:50.629802Z","iopub.status.idle":"2025-09-25T08:38:50.630321Z","shell.execute_reply.started":"2025-09-25T08:38:50.630067Z","shell.execute_reply":"2025-09-25T08:38:50.630087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}